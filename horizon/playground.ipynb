{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"FIFTYONE_CONFIG_PATH\"] = \"/etc/fiftyone/config.json\"\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "from PIL import Image\n",
    "\n",
    "from models.custom import HorizonModel\n",
    "from horizon.dataloaders import (get_train_rgb_dataloader,\n",
    "                                 get_val_rgb_dataloader,\n",
    "                                 get_train_ir16bit_dataloader,\n",
    "                                 get_val_ir16bit_dataloader)\n",
    "from utils.horizon import draw_horizon, postprocess_x_pitch_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = '../yolos/yolov5n6_RGB_D2304-v1_9C.pt'\n",
    "dataset_name = \"SAILING_DATASET_RGB_2023_10\"\n",
    "\n",
    "weights = '../yolos/yolov5n_T16-8_D2306-v0_9C.pt'\n",
    "dataset_name = \"TRAIN_BB_THERMAL_2024_09\"\n",
    "\n",
    "imgsz = 1280 if 'RGB' in weights else 640\n",
    "train_tag, val_tag = \"TRAIN_by_sequence\", \"VAL_by_sequence\"\n",
    "\n",
    "# model = HorizonModel(weights)\n",
    "# for m in model.model:\n",
    "#     print(m.i, m.f, m.type)\n",
    "\n",
    "if \"RGB\" in dataset_name:\n",
    "    train_dataloader = get_train_rgb_dataloader(\n",
    "        dataset=(fo.load_dataset(dataset_name)\n",
    "                .match(F(\"ground_truth_pl.polylines.closed\") == [False])\n",
    "                .match_tags(train_tag)\n",
    "                ),\n",
    "        imgsz=imgsz,\n",
    "    )\n",
    "\n",
    "    val_dataloader = get_val_rgb_dataloader(\n",
    "        dataset=(fo.load_dataset(dataset_name)\n",
    "                .match(F(\"ground_truth_pl.polylines.closed\") == [False])\n",
    "                .match_tags(val_tag)\n",
    "                .take(5000, seed=51)\n",
    "                ),\n",
    "        imgsz=imgsz,\n",
    "    )\n",
    "else:\n",
    "    train_dataloader = get_train_ir16bit_dataloader(\n",
    "        dataset=(fo.load_dataset(dataset_name)\n",
    "                .match(F(\"ground_truth_pl.polylines.closed\") == [False])\n",
    "                .match_tags(train_tag)\n",
    "                ),\n",
    "        imgsz=imgsz,\n",
    "    )\n",
    "\n",
    "    val_dataloader = get_val_ir16bit_dataloader(\n",
    "        dataset=(fo.load_dataset(dataset_name)\n",
    "                .match(F(\"ground_truth_pl.polylines.closed\") == [False])\n",
    "                .match_tags(val_tag)\n",
    "                .take(5000, seed=51)\n",
    "                ),\n",
    "        imgsz=imgsz,\n",
    "    )\n",
    "\n",
    "print(f\"{len(train_dataloader)=}, {len(val_dataloader)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, target in train_dataloader:\n",
    "#     break\n",
    "\n",
    "n = 10\n",
    "print(target[n])\n",
    "I = (image[n].permute(1,2,0) * 255).numpy().astype(np.uint8)\n",
    "I = draw_horizon(I, pitch_theta=np.array(target[n]), diameter=2)\n",
    "I = Image.fromarray(I)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, target in val_dataloader:\n",
    "    break\n",
    "\n",
    "x_pitch, x_theta = model(image.to(model.device))\n",
    "pitch, theta = postprocess_x_pitch_theta(x_pitch, x_theta)\n",
    "pitch, theta = pitch.detach().cpu(), theta.detach().cpu()\n",
    "\n",
    "I = (image[0].permute(1,2,0) * 255).numpy().astype(np.uint8)\n",
    "I = draw_horizon(I, pitch_theta=(pitch[0][0], theta[0][0]), diameter=2)\n",
    "I = Image.fromarray(I)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from utils.general import TQDM_BAR_FORMAT\n",
    "\n",
    "import torch\n",
    "from torch.cuda import amp\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from utils.torch_utils import smart_optimizer, ModelEMA\n",
    "\n",
    "epochs = 300\n",
    "dropout = 0.25\n",
    "\n",
    "for m in model.modules():\n",
    "    if isinstance(m, torch.nn.Dropout) and dropout is not None:\n",
    "        m.p = dropout  # set dropout\n",
    "\n",
    "for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "optimizer = smart_optimizer(model, name=\"Adam\", lr=0.001, momentum=0.9, decay=0.0001)\n",
    "\n",
    "lrf = 0.001  # final lr (fraction of lr0)\n",
    "# lf = lambda x: ((1 + math.cos(x * math.pi / epochs)) / 2) * (1 - lrf) + lrf  # cosine\n",
    "lf = lambda x: (1 - x / epochs) * (1 - lrf) + lrf  # linear\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "loss_pitch = torch.nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "loss_theta = torch.nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "\n",
    "cuda = model.device != 'cpu'\n",
    "scaler = amp.GradScaler(enabled=cuda)\n",
    "\n",
    "ema = ModelEMA(model)\n",
    "best_loss = 1e10\n",
    "\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    t_loss, t_ploss, t_tloss = 0.0, 0.0, 0.0\n",
    "    v_loss, v_ploss, v_tloss = 0.0, 0.0, 0.0\n",
    "    \n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), bar_format=TQDM_BAR_FORMAT)\n",
    "    for i, data in pbar:\n",
    "        images, targets = data\n",
    "        images, targets = images.to(model.device), targets.to(model.device)\n",
    "\n",
    "        # forward\n",
    "        x_pitch, x_theta = model(images)\n",
    "\n",
    "        # process targets\n",
    "        pitch, theta = targets[...,0], targets[...,1]\n",
    "        pitch = (pitch * model.nc_pitch).long().clamp(0, model.nc_pitch - 1)\n",
    "        theta = (theta * model.nc_theta).long().clamp(0, model.nc_theta - 1)\n",
    "\n",
    "        # backward\n",
    "        _loss_pitch = loss_pitch(x_pitch, pitch)\n",
    "        _loss_theta = loss_theta(x_theta, theta)\n",
    "        loss = _loss_pitch + _loss_theta\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Optimize\n",
    "        scaler.unscale_(optimizer)  # unscale gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        if ema:\n",
    "            ema.update(model)\n",
    "\n",
    "        t_loss = (t_loss * i + loss.item()) / (i + 1)  # update mean losses\n",
    "        t_ploss = (t_ploss * i + _loss_pitch.item()) / (i + 1)\n",
    "        t_tloss = (t_tloss * i + _loss_theta.item()) / (i + 1)\n",
    "        mem = '%.3gG' % (torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
    "        losses_str = f\"{t_loss:>12.3g}{t_ploss:>12.3g}{t_tloss:>12.3g}\"\n",
    "        pbar.desc = f\"{'train':>6}{f'{epoch + 1}/{epochs}':>10}{mem:>10}{losses_str}\" + ' ' * 10\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), bar_format=TQDM_BAR_FORMAT)\n",
    "    for i, data in pbar:\n",
    "        images, targets = data\n",
    "        images, targets = images.to(model.device), targets.to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # forward\n",
    "            x_pitch, x_theta = ema.ema(images)\n",
    "\n",
    "            # process targets\n",
    "            pitch, theta = targets[...,0], targets[...,1]\n",
    "            pitch = (pitch * model.nc_pitch).long().clamp(0, ema.ema.nc_pitch - 1)\n",
    "            theta = (theta * model.nc_theta).long().clamp(0, ema.ema.nc_theta - 1)\n",
    "\n",
    "            # store losses\n",
    "            _loss_pitch = loss_pitch(x_pitch, pitch)\n",
    "            _loss_theta = loss_theta(x_theta, theta)\n",
    "            loss = _loss_pitch + _loss_theta\n",
    "\n",
    "            v_loss = (v_loss * i + loss.item()) / (i + 1)  # update mean losses\n",
    "            v_ploss = (v_ploss * i + _loss_pitch.item()) / (i + 1)\n",
    "            v_tloss = (v_tloss * i + _loss_theta.item()) / (i + 1)\n",
    "        mem = '%.3gG' % (torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
    "        losses_str = f\"{v_loss:>12.3g}{v_ploss:>12.3g}{v_tloss:>12.3g}\"\n",
    "        pbar.desc = f\"{'val':>6}{f'{epoch + 1}/{epochs}':>10}{mem:>10}{losses_str}\" + ' ' * 10\n",
    "\n",
    "    if v_loss < best_loss:\n",
    "        best_loss = v_loss\n",
    "        ckpt = {\n",
    "            'epoch': epoch,\n",
    "            'model': deepcopy(ema.ema),  # deepcopy(de_parallel(model)).half(),\n",
    "            'ema': None,  # deepcopy(ema.ema).half(),\n",
    "            'updates': ema.updates,\n",
    "            'optimizer': None,  # optimizer.state_dict(),\n",
    "            'losses': dict(pitch=v_ploss, theta=v_tloss, total=v_loss),\n",
    "            'date': datetime.now().isoformat()}\n",
    "        torch.save(ckpt, f'best.pt')\n",
    "        del ckpt\n",
    "\n",
    "    # Save latest checkpoint\n",
    "    ckpt = {\n",
    "        'epoch': epoch,\n",
    "        'model': deepcopy(ema.ema),  # deepcopy(de_parallel(model)).half(),\n",
    "        'ema': None,  # deepcopy(ema.ema).half(),\n",
    "        'updates': ema.updates,\n",
    "        'optimizer': None,  # optimizer.state_dict(),\n",
    "        'losses': dict(pitch=v_ploss, theta=v_tloss, total=v_loss),\n",
    "        'date': datetime.now().isoformat()}\n",
    "    torch.save(ckpt, f'last.pt')\n",
    "    del ckpt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
