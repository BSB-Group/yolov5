{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import curve_fit\n",
    "import torch\n",
    "\n",
    "from models.custom import HorizonModel\n",
    "import horizon.transforms as T\n",
    "from utils.horizon import draw_horizon\n",
    "\n",
    "def read_sensor_data(sensors_fp: str, sensor=\"rgb_camera\"):\n",
    "    with open(sensors_fp) as f:\n",
    "        data = json.load(f)\n",
    "    return data[sensor]\n",
    "\n",
    "class Undistorter:\n",
    "\n",
    "    def __init__(self, sensor_data):\n",
    "        self.map1, self.map2 = self.init_undistort_maps(sensor_data)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_undistort_maps(sensor_data):\n",
    "        K = np.array(sensor_data[\"K\"])\n",
    "        D = np.array(sensor_data[\"D\"])\n",
    "        Knew = np.array(sensor_data[\"Knew\"])\n",
    "        resolution = sensor_data[\"resolution\"][::-1]\n",
    "        map1, map2 = cv2.fisheye.initUndistortRectifyMap(\n",
    "            K, D, np.eye(3), Knew, resolution, cv2.CV_16SC2)\n",
    "        return map1, map2\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return cv2.remap(img, self.map1, self.map2, \n",
    "                         interpolation=cv2.INTER_LINEAR, \n",
    "                         borderMode=cv2.BORDER_CONSTANT)\n",
    "    \n",
    "def postprocess_horizon(x_pitch, x_theta):    \n",
    "    x_pitch, x_theta = x_pitch.softmax(1), x_theta.softmax(1)\n",
    "    x_pitch = x_pitch.squeeze().cpu().numpy()\n",
    "    x_theta = x_theta.squeeze().cpu().numpy()\n",
    "    x = np.linspace(0, 1, len(x_pitch), endpoint=False)\n",
    "\n",
    "    # curve fitting\n",
    "    def gaussian(x, A, mu, sigma):\n",
    "        return A * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "    # Initial guess for the parameters (amplitude, mean, standard deviation)\n",
    "    initial_pitch_guess = [x_pitch.max(), x_pitch.argmax() / x_pitch.shape[-1], 0.001]\n",
    "    initial_theta_guess = [x_theta.max(), x_theta.argmax() / x_theta.shape[-1], 0.001]\n",
    "\n",
    "    x_data = np.linspace(0, 1, x_pitch.shape[0], endpoint=False)\n",
    "    params_pitch, cov_pitch = curve_fit(gaussian, x_data, x_pitch, p0=initial_pitch_guess)\n",
    "    params_theta, cov_theta = curve_fit(gaussian, x_data, x_theta, p0=initial_theta_guess)\n",
    "\n",
    "    return params_pitch[1], params_theta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 22e72e2 Python-3.10.13 torch-2.1.0 MPS\n",
      "\n",
      "Loaded weights from /Users/kevinserrano/Downloads/tmp/best.pt\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 343/343 [00:20<00:00, 16.40it/s]\n"
     ]
    }
   ],
   "source": [
    "model = HorizonModel(\"/Users/kevinserrano/Downloads/tmp/best.pt\", device=\"mps\")\n",
    "transform = T.horizon_base_RGB(1280)\n",
    "\n",
    "sensors_fpaths = glob.glob(\"/Users/kevinserrano/Downloads/tmp/911/const/sensors.json\")\n",
    "for sensors_fp in sensors_fpaths:\n",
    "    sensors_data = read_sensor_data(sensors_fp)\n",
    "    undistorter = Undistorter(sensors_data)\n",
    "    video_fp = sensors_fp.replace(\"const/sensors.json\", \"rgb.mp4\")\n",
    "\n",
    "    # read video, iterate over frames, convert and write new video\n",
    "    cap = cv2.VideoCapture(video_fp)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    resolution = [1280, 1280] #tuple(sensors_data[\"resolution\"])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(video_fp.replace(\".mp4\", \"_undistorted.mp4\"), fourcc, fps, resolution)\n",
    "\n",
    "    # get number of frames\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=length)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # undistort frame\n",
    "        frame = undistorter(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = transform(image=frame, keypoints=[])[\"image\"]\n",
    "\n",
    "        # predict horizon\n",
    "        with torch.inference_mode():\n",
    "            x_pitch, x_theta = model(frame.unsqueeze(0).to(model.device))\n",
    "            pitch, theta = postprocess_horizon(x_pitch, x_theta)\n",
    "\n",
    "        # draw horizon\n",
    "        frame = draw_horizon((frame.permute(1,2,0) * 255).numpy().astype(np.uint8),\n",
    "                             pitch_theta=[pitch, theta], color=(0, 0, 255), diameter=2)\n",
    "\n",
    "        # write frame\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame)\n",
    "        pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
